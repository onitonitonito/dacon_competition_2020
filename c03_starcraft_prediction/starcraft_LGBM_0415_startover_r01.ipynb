{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"starcraft_LGBM_0415_startover_r01.ipynb","provenance":[{"file_id":"1N8RhZI0O84CrJqaSu7fu8g75eAo57dg5","timestamp":1587368618382}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Nrs-CBkRSRWf","colab_type":"text"},"source":["|   \n","|:--| \n","|<img src ='https://bit.ly/39XPeCc' width=200 align='left'>\n","|<h1>    starcraft_LGBM_0415_startover_r01.ipynb\n","</h1>    \n","\n","### **데이터 분리** (parametric study)\n","> - 80% 20%  Train/Test 자체 Test Data set 으로 모델을 검증 한다.\n","> - Sklearn.train_data_split() 을 이용해서 분리한다.\n","> - 파라메터를 바꿔 가면서 모델의 예측율을 사전 검증"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yj9dS4w29AUl"},"source":["## gDrive 연결\n","> - drive 폴더가 붙은 것을 확인한다.\n","> - drwx------ 4 root root 4.0K Mar 22 11:21 drive"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587422637257,"user_tz":-540,"elapsed":22957,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"cG0ywtEV7uIh","outputId":"6e004276-2e81-4ea4-bde2-47e5dd748973","colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive \n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"187ugqNFuzIG"},"source":["## 모듈 Install / Import "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587422641544,"user_tz":-540,"elapsed":27216,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"KHr7Oekx9AgU","outputId":"bae6ff8a-87c8-41bf-ee03-05b041d74c1b","colab":{"base_uri":"https://localhost:8080/","height":178}},"source":["# 코랩에 없는 라이브러리 설치해주기\n","!pip install bayesian-optimization"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting bayesian-optimization\n","  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.2)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n","Installing collected packages: bayesian-optimization\n","Successfully installed bayesian-optimization-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HZZBn3Ec_bXr","colab":{}},"source":["\"\"\" \n","# WAY-01 = LGBM, WAY-02 = XGBM\n","\"\"\"\n","\n","init_points, n_iter = (20, 50)                      \n","filename_submit = f\"submission_0415_LGBM_{init_points}_{n_iter}_startover_r01.csv\"\n","file_save = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wwg2_k9Sn9oI"},"source":["## 사용함수의 정의"]},{"cell_type":"code","metadata":{"id":"8-RuJudVjOkw","colab_type":"code","colab":{}},"source":["\"\"\" \n","# 기본적인 module import 위치로 작업폴더 변경 getcwd() --> chidr()\n","# HOME 을 지정하고 작업폴더를 HOME 으로 변경.\n","\n","# # for PC\n","# import os\n","# HOME= 'dacon_competition_2020'\n","# dir_base = \"\".join(os.getcwd().partition(HOME)[:2]) + \"\\\\\"\n","# os.chdir(dir_base)  \n","\"\"\"   \n","\n","# for gDrive\n","import os\n","HOME = '/content/drive/My Drive/Colab Notebooks/'\n","os.chdir(HOME)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvDE1HKajTx6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"9c1e7cd7-9827-4b2a-b231-cd57829bce71","executionInfo":{"status":"ok","timestamp":1587422643469,"user_tz":-540,"elapsed":29117,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}}},"source":["from _assets.config_dirs import *\n","from _assets.modules import *\n","from _assets.module_lgbm_model import *"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n","# 화일분석에 필요한 공동폴더를 등록합니다.\n","# - echo = True : SYS.PATH INSERT 상황 보여줌\n","\n","\n","# OS 화일 및 DF 정보조회를 위한 탐색 모듈\n","\n","\n","# LGBM_CV 모델 - Dacon Baseline 참조\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O14CYkrx_Wvr","colab":{}},"source":["import os\n","import sys           \n","import random \n","import warnings          \n","\n","import numpy as np                          # 계산 라이브러리\n","import pandas as pd                         # 데이터 분석 라이브러리\n","import matplotlib.pyplot as plt             # * 그래프 이미지\n","import lightgbm as lgb                      # LightGBM 라이브러리 \n","\n","from tqdm import tqdm                       # 진행바\n","from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n","from sklearn.model_selection import KFold   # K-fold CV    \n","from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n","from functools import partial               # 함수 변수 고정\n","\n","warnings.filterwarnings(\"ignore\")           # 경고 문구 미표시"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2lZ7riQ12br5"},"source":["## 데이터를 불러온다"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587422644686,"user_tz":-540,"elapsed":30302,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"Y_yK7Y7d_esh","outputId":"d9629548-e7eb-4f6a-b1d9-4d9f00d8e780","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%%time\n","\"\"\"\n","# show_infoDF_from(x_train) # *** DATA SHAPE = [ 38,872 x 1,579 ] \n","# to <class 'pandas.core.frame.DataFrame'>\n","# show_infoDF_from(y_train) # *** DATA SHAPE = [ 38,872 x 3 ]\n","# to <class 'numpy.ndarray'> ...  array([1, 1, 0, ..., 0, 1, 0])\n","\"\"\"\n","# x_train = pd.read_csv(dir_base + raw + 'xtra_remake_xtrain_final.csv')  \n","# ytrain = pd.read_csv(dir_base + remake + 'df_ytrain_remake.csv')  \n","# y_train = ytrain['winner'].values    \n","\n","\n","_df1 = pd.read_csv(dir_base + raw + 'X1_train.csv')\n","\n","x_train = _df1.iloc[:,:-1]\n","y_train = _df1.loc[:, 'Y'].to_numpy()     \n","\n","# x_train.shape, y_train.shape  # ((31097, 27), (31097,))\n","# type(y_train)                 # numpy.ndarray\n","# y_train                       # array([1, 1, 0, ..., 1, 1, 0])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["CPU times: user 77.9 ms, sys: 51.1 ms, total: 129 ms\n","Wall time: 998 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N0IWulmegR7U"},"source":["## LGBM Classifier 모델 적용\n"," -  Light Gradient Boost Method 적용 - [출처] :  YW & YY's Python, Machine & Deep Learning\n"," > - Light GBM: A Highly Efficient Gradient Boosting Decision Tree 논문 리뷰\n"," > - [Light GBM 모델 설명 및 사용법](https://greeksharifa.github.io/machine_learning/2019/12/09/Light-GBM/)\n","\n"," > 다중 분류, 클릭 예측, 순위 학습 등에 주로 사용되는 Gradient Boosting Decision Tree (GBDT)는 굉장히 유용한 머신러닝 알고리즘이며, XGBoost나 pGBRT 등 효율적인 기법의 설계를 가능하게 하였다. 이러한 구현은 많은 엔지니어링 최적화를 이룩하였지만 고차원이고 큰 데이터 셋에서는 만족스러운 결과를 내지 못하는 경우도 있었다. 왜냐하면 모든 가능한 분할점에 대해 정보 획득을 평가하기 위해 데이터 개체 전부를 스캔해야 했기 때문이다. 이는 당연하게도, 굉장히 시간 소모적이다.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587422763176,"user_tz":-540,"elapsed":148778,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"Ny69by1mUWln","outputId":"484f7aeb-8fdc-4f32-9311-b24232e28677","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","\"\"\"\n","# 처음 5회 랜덤 값으로 score 계산 후, 30회 최적화 = Original Baseline!\n","# lgbBO.maximize(init_points=5, n_iter=30) \n","\"\"\"\n","\n","var_fixed = partial(                        # 모델과 관련없는 변수 고정\n","                  lgb_cv, \n","                  x_data=x_train, \n","                  y_data=y_train, \n","                  n_splits=5, \n","                  output='score',\n","                ) \n","\n","lgbBO = BayesianOptimization(                # 베이지안 최적화 범위 설정\n","      var_fixed, \n","      {\n","          'colsample_bytree': (0, 1),        # colsample_bytree, 범위(0~1)\n","          'learning_rate': (0.0001, 0.1),    # learning_rate,    범위(0.0001~0.1)\n","          'n_estimators': (16, 62),        # n_estimators,     범위(16~1024)\n","          'num_leaves': (16, 62),          # num_leaves,       범위(16~1024)\n","          'reg_alpha': (0, 10),              # reg_alpha,        범위(0~10)\n","          'reg_lambda': (0, 50),             # reg_lambda,       범위(0~50)\n","          'subsample': (0, 1),               # subsample,        범위(0~1)\n","      }, \n","        # random_state=random.randrange(50000)   # 초기 값  = 50000\n","        random_state=random.randrange( 4321)   # 시드 고정 = 4321\n","  )\n","\n","lgbBO.maximize(init_points, n_iter)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["|   iter    |  target   | colsam... | learni... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n","-------------------------------------------------------------------------------------------------------------\n","| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6412  \u001b[0m | \u001b[0m 0.2254  \u001b[0m | \u001b[0m 0.09283 \u001b[0m | \u001b[0m 43.58   \u001b[0m | \u001b[0m 36.94   \u001b[0m | \u001b[0m 3.864   \u001b[0m | \u001b[0m 3.129   \u001b[0m | \u001b[0m 0.974   \u001b[0m |\n","| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6379  \u001b[0m | \u001b[0m 0.7366  \u001b[0m | \u001b[0m 0.07346 \u001b[0m | \u001b[0m 23.55   \u001b[0m | \u001b[0m 49.91   \u001b[0m | \u001b[0m 7.385   \u001b[0m | \u001b[0m 26.83   \u001b[0m | \u001b[0m 0.6006  \u001b[0m |\n","| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 0.153   \u001b[0m | \u001b[0m 0.07564 \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 20.33   \u001b[0m | \u001b[0m 1.83    \u001b[0m | \u001b[0m 41.5    \u001b[0m | \u001b[0m 0.5567  \u001b[0m |\n","| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6423  \u001b[0m | \u001b[95m 0.4161  \u001b[0m | \u001b[95m 0.07741 \u001b[0m | \u001b[95m 59.93   \u001b[0m | \u001b[95m 46.74   \u001b[0m | \u001b[95m 9.412   \u001b[0m | \u001b[95m 48.66   \u001b[0m | \u001b[95m 0.6822  \u001b[0m |\n","| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6337  \u001b[0m | \u001b[0m 0.2152  \u001b[0m | \u001b[0m 0.06103 \u001b[0m | \u001b[0m 34.0    \u001b[0m | \u001b[0m 55.15   \u001b[0m | \u001b[0m 1.045   \u001b[0m | \u001b[0m 0.4995  \u001b[0m | \u001b[0m 0.8293  \u001b[0m |\n","| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6339  \u001b[0m | \u001b[0m 0.6926  \u001b[0m | \u001b[0m 0.02188 \u001b[0m | \u001b[0m 30.43   \u001b[0m | \u001b[0m 19.24   \u001b[0m | \u001b[0m 7.054   \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 0.8937  \u001b[0m |\n","| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6357  \u001b[0m | \u001b[0m 0.3423  \u001b[0m | \u001b[0m 0.06896 \u001b[0m | \u001b[0m 30.85   \u001b[0m | \u001b[0m 50.83   \u001b[0m | \u001b[0m 4.221   \u001b[0m | \u001b[0m 42.73   \u001b[0m | \u001b[0m 0.6863  \u001b[0m |\n","| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6228  \u001b[0m | \u001b[0m 0.08584 \u001b[0m | \u001b[0m 0.03566 \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 40.85   \u001b[0m | \u001b[0m 9.353   \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 0.1789  \u001b[0m |\n","| \u001b[0m 9       \u001b[0m | \u001b[0m 0.626   \u001b[0m | \u001b[0m 0.1213  \u001b[0m | \u001b[0m 0.03446 \u001b[0m | \u001b[0m 40.09   \u001b[0m | \u001b[0m 29.21   \u001b[0m | \u001b[0m 3.951   \u001b[0m | \u001b[0m 38.25   \u001b[0m | \u001b[0m 0.9777  \u001b[0m |\n","| \u001b[95m 10      \u001b[0m | \u001b[95m 0.6432  \u001b[0m | \u001b[95m 0.9834  \u001b[0m | \u001b[95m 0.06952 \u001b[0m | \u001b[95m 58.38   \u001b[0m | \u001b[95m 56.37   \u001b[0m | \u001b[95m 1.945   \u001b[0m | \u001b[95m 36.06   \u001b[0m | \u001b[95m 0.4372  \u001b[0m |\n","| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6381  \u001b[0m | \u001b[0m 0.8213  \u001b[0m | \u001b[0m 0.07264 \u001b[0m | \u001b[0m 19.49   \u001b[0m | \u001b[0m 32.97   \u001b[0m | \u001b[0m 1.575   \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 0.876   \u001b[0m |\n","| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6324  \u001b[0m | \u001b[0m 0.2785  \u001b[0m | \u001b[0m 0.001491\u001b[0m | \u001b[0m 19.55   \u001b[0m | \u001b[0m 47.88   \u001b[0m | \u001b[0m 9.377   \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 0.7719  \u001b[0m |\n","| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6353  \u001b[0m | \u001b[0m 0.2537  \u001b[0m | \u001b[0m 0.09106 \u001b[0m | \u001b[0m 35.28   \u001b[0m | \u001b[0m 54.31   \u001b[0m | \u001b[0m 9.38    \u001b[0m | \u001b[0m 49.53   \u001b[0m | \u001b[0m 0.07266 \u001b[0m |\n","| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6406  \u001b[0m | \u001b[0m 0.7794  \u001b[0m | \u001b[0m 0.0768  \u001b[0m | \u001b[0m 24.62   \u001b[0m | \u001b[0m 62.0    \u001b[0m | \u001b[0m 6.57    \u001b[0m | \u001b[0m 2.968   \u001b[0m | \u001b[0m 0.07883 \u001b[0m |\n","| \u001b[0m 15      \u001b[0m | \u001b[0m 0.643   \u001b[0m | \u001b[0m 0.6944  \u001b[0m | \u001b[0m 0.07043 \u001b[0m | \u001b[0m 41.06   \u001b[0m | \u001b[0m 34.51   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 10.88   \u001b[0m | \u001b[0m 0.06288 \u001b[0m |\n","| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6088  \u001b[0m | \u001b[0m 0.02062 \u001b[0m | \u001b[0m 0.07436 \u001b[0m | \u001b[0m 45.9    \u001b[0m | \u001b[0m 55.67   \u001b[0m | \u001b[0m 9.814   \u001b[0m | \u001b[0m 19.3    \u001b[0m | \u001b[0m 0.6321  \u001b[0m |\n","| \u001b[0m 17      \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 0.04324 \u001b[0m | \u001b[0m 0.03503 \u001b[0m | \u001b[0m 27.22   \u001b[0m | \u001b[0m 28.17   \u001b[0m | \u001b[0m 0.3253  \u001b[0m | \u001b[0m 20.64   \u001b[0m | \u001b[0m 0.7583  \u001b[0m |\n","| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6366  \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 0.02503 \u001b[0m | \u001b[0m 43.4    \u001b[0m | \u001b[0m 29.06   \u001b[0m | \u001b[0m 6.642   \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 0.9984  \u001b[0m |\n","| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 0.4308  \u001b[0m | \u001b[0m 0.07344 \u001b[0m | \u001b[0m 27.89   \u001b[0m | \u001b[0m 27.94   \u001b[0m | \u001b[0m 1.484   \u001b[0m | \u001b[0m 6.929   \u001b[0m | \u001b[0m 0.5122  \u001b[0m |\n","| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6335  \u001b[0m | \u001b[0m 0.6671  \u001b[0m | \u001b[0m 0.007969\u001b[0m | \u001b[0m 26.31   \u001b[0m | \u001b[0m 26.52   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 8.649   \u001b[0m | \u001b[0m 0.04882 \u001b[0m |\n","| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6374  \u001b[0m | \u001b[0m 0.7794  \u001b[0m | \u001b[0m 0.03339 \u001b[0m | \u001b[0m 60.4    \u001b[0m | \u001b[0m 17.25   \u001b[0m | \u001b[0m 8.543   \u001b[0m | \u001b[0m 49.31   \u001b[0m | \u001b[0m 0.8847  \u001b[0m |\n","| \u001b[95m 22      \u001b[0m | \u001b[95m 0.6432  \u001b[0m | \u001b[95m 0.8669  \u001b[0m | \u001b[95m 0.08223 \u001b[0m | \u001b[95m 60.68   \u001b[0m | \u001b[95m 16.31   \u001b[0m | \u001b[95m 6.258   \u001b[0m | \u001b[95m 0.1997  \u001b[0m | \u001b[95m 0.1745  \u001b[0m |\n","| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6278  \u001b[0m | \u001b[0m 0.5998  \u001b[0m | \u001b[0m 0.05714 \u001b[0m | \u001b[0m 16.81   \u001b[0m | \u001b[0m 19.9    \u001b[0m | \u001b[0m 9.186   \u001b[0m | \u001b[0m 47.47   \u001b[0m | \u001b[0m 0.06228 \u001b[0m |\n","| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6295  \u001b[0m | \u001b[0m 0.7358  \u001b[0m | \u001b[0m 0.01039 \u001b[0m | \u001b[0m 18.77   \u001b[0m | \u001b[0m 60.06   \u001b[0m | \u001b[0m 1.979   \u001b[0m | \u001b[0m 49.35   \u001b[0m | \u001b[0m 0.2948  \u001b[0m |\n","| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6269  \u001b[0m | \u001b[0m 0.1466  \u001b[0m | \u001b[0m 0.03909 \u001b[0m | \u001b[0m 16.27   \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 7.755   \u001b[0m | \u001b[0m 0.9679  \u001b[0m | \u001b[0m 0.05189 \u001b[0m |\n","| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.8362  \u001b[0m | \u001b[0m 0.08736 \u001b[0m | \u001b[0m 61.66   \u001b[0m | \u001b[0m 58.75   \u001b[0m | \u001b[0m 3.524   \u001b[0m | \u001b[0m 0.5011  \u001b[0m | \u001b[0m 0.1423  \u001b[0m |\n","| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6352  \u001b[0m | \u001b[0m 0.73    \u001b[0m | \u001b[0m 0.0386  \u001b[0m | \u001b[0m 16.04   \u001b[0m | \u001b[0m 58.17   \u001b[0m | \u001b[0m 1.29    \u001b[0m | \u001b[0m 17.73   \u001b[0m | \u001b[0m 0.1751  \u001b[0m |\n","| \u001b[95m 28      \u001b[0m | \u001b[95m 0.6444  \u001b[0m | \u001b[95m 0.9364  \u001b[0m | \u001b[95m 0.08925 \u001b[0m | \u001b[95m 61.83   \u001b[0m | \u001b[95m 34.98   \u001b[0m | \u001b[95m 0.09093 \u001b[0m | \u001b[95m 49.71   \u001b[0m | \u001b[95m 0.6353  \u001b[0m |\n","| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 0.7686  \u001b[0m | \u001b[0m 0.01132 \u001b[0m | \u001b[0m 36.1    \u001b[0m | \u001b[0m 21.0    \u001b[0m | \u001b[0m 8.029   \u001b[0m | \u001b[0m 49.61   \u001b[0m | \u001b[0m 0.6906  \u001b[0m |\n","| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6372  \u001b[0m | \u001b[0m 0.9228  \u001b[0m | \u001b[0m 0.03027 \u001b[0m | \u001b[0m 59.15   \u001b[0m | \u001b[0m 16.29   \u001b[0m | \u001b[0m 0.0389  \u001b[0m | \u001b[0m 20.88   \u001b[0m | \u001b[0m 0.4462  \u001b[0m |\n","| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 0.01476 \u001b[0m | \u001b[0m 0.09872 \u001b[0m | \u001b[0m 61.19   \u001b[0m | \u001b[0m 61.52   \u001b[0m | \u001b[0m 1.607   \u001b[0m | \u001b[0m 48.94   \u001b[0m | \u001b[0m 0.8519  \u001b[0m |\n","| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6298  \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 0.01059 \u001b[0m | \u001b[0m 17.3    \u001b[0m | \u001b[0m 33.85   \u001b[0m | \u001b[0m 1.834   \u001b[0m | \u001b[0m 49.46   \u001b[0m | \u001b[0m 0.9569  \u001b[0m |\n","| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6388  \u001b[0m | \u001b[0m 0.7403  \u001b[0m | \u001b[0m 0.06724 \u001b[0m | \u001b[0m 16.9    \u001b[0m | \u001b[0m 40.07   \u001b[0m | \u001b[0m 1.904   \u001b[0m | \u001b[0m 0.4836  \u001b[0m | \u001b[0m 0.6972  \u001b[0m |\n","| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.9911  \u001b[0m | \u001b[0m 0.04425 \u001b[0m | \u001b[0m 58.84   \u001b[0m | \u001b[0m 33.18   \u001b[0m | \u001b[0m 0.2305  \u001b[0m | \u001b[0m 0.4883  \u001b[0m | \u001b[0m 0.7381  \u001b[0m |\n","| \u001b[0m 35      \u001b[0m | \u001b[0m 0.632   \u001b[0m | \u001b[0m 0.9151  \u001b[0m | \u001b[0m 0.01953 \u001b[0m | \u001b[0m 38.83   \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.4229  \u001b[0m |\n","| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6357  \u001b[0m | \u001b[0m 0.8008  \u001b[0m | \u001b[0m 0.02493 \u001b[0m | \u001b[0m 61.23   \u001b[0m | \u001b[0m 17.72   \u001b[0m | \u001b[0m 9.201   \u001b[0m | \u001b[0m 28.49   \u001b[0m | \u001b[0m 0.8237  \u001b[0m |\n","| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6379  \u001b[0m | \u001b[0m 0.9955  \u001b[0m | \u001b[0m 0.05063 \u001b[0m | \u001b[0m 28.65   \u001b[0m | \u001b[0m 34.4    \u001b[0m | \u001b[0m 7.682   \u001b[0m | \u001b[0m 2.537   \u001b[0m | \u001b[0m 0.7445  \u001b[0m |\n","| \u001b[0m 38      \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.7827  \u001b[0m | \u001b[0m 0.06669 \u001b[0m | \u001b[0m 16.93   \u001b[0m | \u001b[0m 57.49   \u001b[0m | \u001b[0m 9.624   \u001b[0m | \u001b[0m 39.67   \u001b[0m | \u001b[0m 0.2796  \u001b[0m |\n","| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5863  \u001b[0m | \u001b[0m 0.01352 \u001b[0m | \u001b[0m 0.06206 \u001b[0m | \u001b[0m 17.13   \u001b[0m | \u001b[0m 16.31   \u001b[0m | \u001b[0m 1.208   \u001b[0m | \u001b[0m 46.7    \u001b[0m | \u001b[0m 0.9527  \u001b[0m |\n","| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6423  \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 0.04119 \u001b[0m | \u001b[0m 60.71   \u001b[0m | \u001b[0m 61.77   \u001b[0m | \u001b[0m 0.06565 \u001b[0m | \u001b[0m 17.76   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n","| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6292  \u001b[0m | \u001b[0m 0.8723  \u001b[0m | \u001b[0m 0.01662 \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 30.35   \u001b[0m | \u001b[0m 9.87    \u001b[0m | \u001b[0m 22.56   \u001b[0m | \u001b[0m 0.6562  \u001b[0m |\n","| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6283  \u001b[0m | \u001b[0m 0.8808  \u001b[0m | \u001b[0m 0.01671 \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 16.72   \u001b[0m | \u001b[0m 0.8967  \u001b[0m | \u001b[0m 2.101   \u001b[0m | \u001b[0m 0.5807  \u001b[0m |\n","| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6425  \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 0.0798  \u001b[0m | \u001b[0m 60.75   \u001b[0m | \u001b[0m 61.61   \u001b[0m | \u001b[0m 9.365   \u001b[0m | \u001b[0m 36.39   \u001b[0m | \u001b[0m 0.104   \u001b[0m |\n","| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6443  \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 0.05964 \u001b[0m | \u001b[0m 61.89   \u001b[0m | \u001b[0m 38.89   \u001b[0m | \u001b[0m 0.07187 \u001b[0m | \u001b[0m 30.32   \u001b[0m | \u001b[0m 0.485   \u001b[0m |\n","| \u001b[0m 45      \u001b[0m | \u001b[0m 0.633   \u001b[0m | \u001b[0m 0.5628  \u001b[0m | \u001b[0m 0.01566 \u001b[0m | \u001b[0m 57.42   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.06197 \u001b[0m | \u001b[0m 45.48   \u001b[0m | \u001b[0m 0.9947  \u001b[0m |\n","| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6323  \u001b[0m | \u001b[0m 0.8602  \u001b[0m | \u001b[0m 0.006459\u001b[0m | \u001b[0m 31.72   \u001b[0m | \u001b[0m 61.64   \u001b[0m | \u001b[0m 0.1412  \u001b[0m | \u001b[0m 21.84   \u001b[0m | \u001b[0m 0.9693  \u001b[0m |\n","| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6312  \u001b[0m | \u001b[0m 0.9546  \u001b[0m | \u001b[0m 0.008459\u001b[0m | \u001b[0m 50.32   \u001b[0m | \u001b[0m 61.48   \u001b[0m | \u001b[0m 9.443   \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 0.8684  \u001b[0m |\n","| \u001b[0m 48      \u001b[0m | \u001b[0m 0.63    \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 0.02561 \u001b[0m | \u001b[0m 21.64   \u001b[0m | \u001b[0m 44.08   \u001b[0m | \u001b[0m 8.937   \u001b[0m | \u001b[0m 49.14   \u001b[0m | \u001b[0m 0.07751 \u001b[0m |\n","| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6273  \u001b[0m | \u001b[0m 0.9258  \u001b[0m | \u001b[0m 0.004005\u001b[0m | \u001b[0m 38.42   \u001b[0m | \u001b[0m 61.36   \u001b[0m | \u001b[0m 0.6328  \u001b[0m | \u001b[0m 49.0    \u001b[0m | \u001b[0m 0.5718  \u001b[0m |\n","| \u001b[0m 50      \u001b[0m | \u001b[0m 0.638   \u001b[0m | \u001b[0m 0.8792  \u001b[0m | \u001b[0m 0.05522 \u001b[0m | \u001b[0m 41.58   \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 39.68   \u001b[0m | \u001b[0m 0.06676 \u001b[0m |\n","| \u001b[0m 51      \u001b[0m | \u001b[0m 0.6273  \u001b[0m | \u001b[0m 0.3612  \u001b[0m | \u001b[0m 0.007634\u001b[0m | \u001b[0m 17.42   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 0.2369  \u001b[0m | \u001b[0m 0.2118  \u001b[0m | \u001b[0m 0.5005  \u001b[0m |\n","| \u001b[0m 52      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 0.7555  \u001b[0m | \u001b[0m 0.06774 \u001b[0m | \u001b[0m 44.66   \u001b[0m | \u001b[0m 41.19   \u001b[0m | \u001b[0m 1.116   \u001b[0m | \u001b[0m 48.74   \u001b[0m | \u001b[0m 0.04163 \u001b[0m |\n","| \u001b[0m 53      \u001b[0m | \u001b[0m 0.6399  \u001b[0m | \u001b[0m 0.9644  \u001b[0m | \u001b[0m 0.09616 \u001b[0m | \u001b[0m 48.15   \u001b[0m | \u001b[0m 59.41   \u001b[0m | \u001b[0m 0.4665  \u001b[0m | \u001b[0m 1.189   \u001b[0m | \u001b[0m 0.8585  \u001b[0m |\n","| \u001b[0m 54      \u001b[0m | \u001b[0m 0.6399  \u001b[0m | \u001b[0m 0.9607  \u001b[0m | \u001b[0m 0.02517 \u001b[0m | \u001b[0m 56.39   \u001b[0m | \u001b[0m 50.14   \u001b[0m | \u001b[0m 0.1839  \u001b[0m | \u001b[0m 8.195   \u001b[0m | \u001b[0m 0.9939  \u001b[0m |\n","| \u001b[0m 55      \u001b[0m | \u001b[0m 0.6425  \u001b[0m | \u001b[0m 0.8114  \u001b[0m | \u001b[0m 0.05603 \u001b[0m | \u001b[0m 61.82   \u001b[0m | \u001b[0m 29.27   \u001b[0m | \u001b[0m 7.027   \u001b[0m | \u001b[0m 44.92   \u001b[0m | \u001b[0m 0.01711 \u001b[0m |\n","| \u001b[0m 56      \u001b[0m | \u001b[0m 0.6414  \u001b[0m | \u001b[0m 0.9597  \u001b[0m | \u001b[0m 0.09723 \u001b[0m | \u001b[0m 27.13   \u001b[0m | \u001b[0m 46.35   \u001b[0m | \u001b[0m 0.6938  \u001b[0m | \u001b[0m 9.576   \u001b[0m | \u001b[0m 0.9294  \u001b[0m |\n","| \u001b[0m 57      \u001b[0m | \u001b[0m 0.6329  \u001b[0m | \u001b[0m 0.9697  \u001b[0m | \u001b[0m 0.01922 \u001b[0m | \u001b[0m 58.97   \u001b[0m | \u001b[0m 16.86   \u001b[0m | \u001b[0m 8.578   \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 0.4981  \u001b[0m |\n","| \u001b[0m 58      \u001b[0m | \u001b[0m 0.6424  \u001b[0m | \u001b[0m 0.4433  \u001b[0m | \u001b[0m 0.09363 \u001b[0m | \u001b[0m 56.27   \u001b[0m | \u001b[0m 16.71   \u001b[0m | \u001b[0m 0.04151 \u001b[0m | \u001b[0m 2.764   \u001b[0m | \u001b[0m 0.7493  \u001b[0m |\n","| \u001b[0m 59      \u001b[0m | \u001b[0m 0.6306  \u001b[0m | \u001b[0m 0.8693  \u001b[0m | \u001b[0m 0.04087 \u001b[0m | \u001b[0m 20.4    \u001b[0m | \u001b[0m 16.23   \u001b[0m | \u001b[0m 9.772   \u001b[0m | \u001b[0m 33.97   \u001b[0m | \u001b[0m 0.9118  \u001b[0m |\n","| \u001b[0m 60      \u001b[0m | \u001b[0m 0.638   \u001b[0m | \u001b[0m 0.9989  \u001b[0m | \u001b[0m 0.08926 \u001b[0m | \u001b[0m 17.24   \u001b[0m | \u001b[0m 46.6    \u001b[0m | \u001b[0m 2.14    \u001b[0m | \u001b[0m 32.78   \u001b[0m | \u001b[0m 0.9706  \u001b[0m |\n","| \u001b[0m 61      \u001b[0m | \u001b[0m 0.6385  \u001b[0m | \u001b[0m 0.9443  \u001b[0m | \u001b[0m 0.08216 \u001b[0m | \u001b[0m 28.18   \u001b[0m | \u001b[0m 61.84   \u001b[0m | \u001b[0m 9.983   \u001b[0m | \u001b[0m 36.55   \u001b[0m | \u001b[0m 0.7487  \u001b[0m |\n","| \u001b[0m 62      \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.974   \u001b[0m | \u001b[0m 0.03027 \u001b[0m | \u001b[0m 61.7    \u001b[0m | \u001b[0m 49.87   \u001b[0m | \u001b[0m 5.316   \u001b[0m | \u001b[0m 29.52   \u001b[0m | \u001b[0m 0.1088  \u001b[0m |\n","| \u001b[0m 63      \u001b[0m | \u001b[0m 0.6367  \u001b[0m | \u001b[0m 0.9962  \u001b[0m | \u001b[0m 0.08858 \u001b[0m | \u001b[0m 16.29   \u001b[0m | \u001b[0m 33.99   \u001b[0m | \u001b[0m 7.413   \u001b[0m | \u001b[0m 7.111   \u001b[0m | \u001b[0m 0.7364  \u001b[0m |\n","| \u001b[0m 64      \u001b[0m | \u001b[0m 0.6439  \u001b[0m | \u001b[0m 0.8339  \u001b[0m | \u001b[0m 0.05816 \u001b[0m | \u001b[0m 61.14   \u001b[0m | \u001b[0m 26.69   \u001b[0m | \u001b[0m 0.8987  \u001b[0m | \u001b[0m 9.841   \u001b[0m | \u001b[0m 0.4713  \u001b[0m |\n","| \u001b[0m 65      \u001b[0m | \u001b[0m 0.638   \u001b[0m | \u001b[0m 0.8743  \u001b[0m | \u001b[0m 0.03589 \u001b[0m | \u001b[0m 51.12   \u001b[0m | \u001b[0m 61.1    \u001b[0m | \u001b[0m 9.691   \u001b[0m | \u001b[0m 44.81   \u001b[0m | \u001b[0m 0.07315 \u001b[0m |\n","| \u001b[0m 66      \u001b[0m | \u001b[0m 0.643   \u001b[0m | \u001b[0m 0.9504  \u001b[0m | \u001b[0m 0.09749 \u001b[0m | \u001b[0m 35.38   \u001b[0m | \u001b[0m 29.48   \u001b[0m | \u001b[0m 0.8601  \u001b[0m | \u001b[0m 1.048   \u001b[0m | \u001b[0m 0.547   \u001b[0m |\n","| \u001b[0m 67      \u001b[0m | \u001b[0m 0.6311  \u001b[0m | \u001b[0m 0.8483  \u001b[0m | \u001b[0m 0.00477 \u001b[0m | \u001b[0m 16.04   \u001b[0m | \u001b[0m 39.69   \u001b[0m | \u001b[0m 0.412   \u001b[0m | \u001b[0m 9.403   \u001b[0m | \u001b[0m 0.001482\u001b[0m |\n","| \u001b[0m 68      \u001b[0m | \u001b[0m 0.6393  \u001b[0m | \u001b[0m 0.9567  \u001b[0m | \u001b[0m 0.09662 \u001b[0m | \u001b[0m 25.48   \u001b[0m | \u001b[0m 28.49   \u001b[0m | \u001b[0m 9.321   \u001b[0m | \u001b[0m 40.69   \u001b[0m | \u001b[0m 0.9844  \u001b[0m |\n","| \u001b[0m 69      \u001b[0m | \u001b[0m 0.636   \u001b[0m | \u001b[0m 0.8239  \u001b[0m | \u001b[0m 0.08778 \u001b[0m | \u001b[0m 17.25   \u001b[0m | \u001b[0m 61.9    \u001b[0m | \u001b[0m 8.129   \u001b[0m | \u001b[0m 28.45   \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n","| \u001b[0m 70      \u001b[0m | \u001b[0m 0.6442  \u001b[0m | \u001b[0m 0.917   \u001b[0m | \u001b[0m 0.09254 \u001b[0m | \u001b[0m 53.85   \u001b[0m | \u001b[0m 40.04   \u001b[0m | \u001b[0m 3.606   \u001b[0m | \u001b[0m 45.69   \u001b[0m | \u001b[0m 0.9376  \u001b[0m |\n","=============================================================================================================\n","CPU times: user 1h 29s, sys: 5min 24s, total: 1h 5min 53s\n","Wall time: 1min 58s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CfHi_LZ4O1_l"},"source":["## 모델 학습 및 검증\n","- Model Tuning & Evaluation\n","\n","> 1. AUC가 가장 높은 하이퍼 파라미터를 사용해 최종 모델을 얻습니다.\n","> 1. 훈련 세트와 같은 방법으로 테스트 세트에서 Feature를 추출합니다.\n","> 1. 최종 모델을 사용해 예측을 수행합니다.\n","> 1. 예측 결과를 submission.csv로 저장합니다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7UMIvW62UWhn","colab":{}},"source":["\"\"\"\n","# Light Gradient Boost Method 적용\n","# Light GBM: A Highly Efficient Gradient Boosting Decision Tree 논문 리뷰\n","# https://greeksharifa.github.io/machine_learning/2019/12/09/Light-GBM/)\n","\"\"\"\n","params = lgbBO.max['params']\n","\n","models = lgb_cv(\n","        num_leaves=       params['num_leaves'], \n","        learning_rate=    params['learning_rate'], \n","        n_estimators=     params['n_estimators'], \n","        subsample=        params['subsample'], \n","        colsample_bytree= params['colsample_bytree'], \n","        reg_alpha=        params['reg_alpha'], \n","        reg_lambda=       params['reg_lambda'], \n","        x_data=x_train, \n","        y_data=y_train, \n","        n_splits=5, \n","        output='model',\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W9d6ImndX5zO"},"source":["## TEST를 풀기위해, 학습데이터로 변경 (data_preps)\n","- df_xtrain_final.shape   # (38872, 1579)\n","- df_xtest_final.shape   # (16787, 1579)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"20YeuGYXUWZ3","colab":{}},"source":["\"\"\"\n","# 테스트용 데이터를 전처리 해서 분석 준비 ... (시간소요) 미리 저장한 화일을 불러온다\n","# 저장했으면 비활성 처리\n","# x_test, _ = data_preparation(test, answer=False)                 # [ 28,714,849 x 6 ] ... 30%\n","# x_test.to_csv(dir_base + remake + 'df_xtest_remake.csv')\n","# x_test = pd.read_csv(dir_base + remake + 'df_xtest_remake.csv')  # [  16,787 x 27 ]\n","\"\"\"\n","# x_test = pd.read_csv(dir_base + remake + 'xtra_remake_xtest_final.csv')    # *** DATA SHAPE = [ 16,787 x 27 ]\n","\n","_df2 = pd.read_csv(dir_base + raw + 'X1_test.csv')\n","x_test = _df2.iloc[:,:-1]\n","y_test = _df2.loc[:, 'Y']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eszuSZ2pfVX","colab_type":"code","outputId":"07352508-66b4-4d57-8d00-5d09a3d3ad71","executionInfo":{"status":"ok","timestamp":1587422765271,"user_tz":-540,"elapsed":150849,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["x_test.shape, y_test.shape  # ((31097, 27), (31097,))\n","type(y_test)                 # numpy.ndarray\n","y_test                       # array([1, 1, 0, ..., 1, 1, 0])"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       1\n","2       0\n","3       0\n","4       0\n","       ..\n","7770    1\n","7771    0\n","7772    0\n","7773    1\n","7774    0\n","Name: Y, Length: 7775, dtype: int64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RxraHMvoufLe"},"source":["## 예측결과 Submission 화일 만들기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k9HevRoDUWUC","colab":{}},"source":["\"\"\"\n","# pd.read_csv('data/sample_submission.csv', index_col=0)\n","# sample_submission = pd.read_csv(dir_base + sub_base + \"sample_submission.csv\")\n","\"\"\"\n","\n","preds = []\n","\n","for model in models:\n","    pred = model.predict_proba(x_test)[:, 1]\n","    preds.append(pred)\n","    \n","pred = np.mean(preds, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"StkAS1f-Gpbx","colab_type":"code","colab":{}},"source":["\"\"\"\n","# submission = pd.read_csv(dir_base + raw + \"sample_submission.csv\", index_col='game_id') \n","# submission = pd.DataFrame(pred, columns=['winner'])\n","\n","# submission['winner'] = pred\n","\"\"\"\n","\n","\n","submission = pd.DataFrame(pred, columns=['winner'])\n","# submission.to_csv(dir_base + submit + filename_submit, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh6qXnFFzf_r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"663900c0-5dd6-4bdb-9803-636a9541752e","executionInfo":{"status":"ok","timestamp":1587423356214,"user_tz":-540,"elapsed":650,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}}},"source":["\"\"\"\n","# submission = pd.read_csv(dir_base + raw + \"sample_submission.csv\") \n","# submission['winner'] = pred\n","\"\"\"\n","if file_save:\n","    submission.to_csv(dir_base + submit + filename_submit, index=False)\n","else:\n","    print('*** SAVING FILE SKIPPED!! ***')   "],"execution_count":17,"outputs":[{"output_type":"stream","text":["*** SAVING FILE SKIPPED!! ***\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fvXCgOzqJVag","colab_type":"code","outputId":"54e63150-cb1d-44b2-f2c8-ceb044dd19ed","executionInfo":{"status":"ok","timestamp":1587422765280,"user_tz":-540,"elapsed":150839,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\"\n","#  자체 스코어를 파악해 본다 = 정답률 60.37 % \n","# - True     4694\n","# - False    3081\n","\"\"\"\n","\n","df_score =  submission.copy()             # deep copy\n","df_score['Y-pred'] = df_score.winner.apply(lambda x: 1 if x > 0.5 else 0)\n","df_score['Y'] = y_test\n","df_score['check-sum'] = (df_score['Y-pred'] == df_score['Y'])\n","\n","_ = df_score['check-sum'].value_counts().to_list()\n","score = _[0]/(_[0]+_[1])\n","print(f\"*** SCORE = {score * 100:0.7} %\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["*** SCORE = 60.25723 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PsES-_o-TsO0","colab_type":"text"},"source":["# LGBM Parametric Study\n","\n","| NUM | SEED | RANDOM | ITERATION | n_ESTIMATION | num_LEAF | TIME_SPEND| PREDICTION |\n","|:---:|-----:|---:|---:|-----:|-----:|----------:|:--------:|\n","| 1   | 50000| 20 | 50 | 1024 | 1024 | 47.28 min | 60.369 % |\n","| 2   |  4321| 20 | 50 |  500 |  500 | 20.37 min | 60.617 % |\n","| 3   |  4321| 20 | 50 |  250 |  250 |  8.00 min | 60.758 % |\n","| 4   |  4321| 20 | 50 |  125 |  125 |  3.29 min | 60.694 % |\n","| 5   |  4321| 20 | 50 |   62 |   62 |  1.55 min | 60.694 % |\n","|  -  |\n","| 1   | 50000| 15 | 75 | 1024 | 1024 | 52.20 min | 60.681 % |\n","| 2   |  4321| 15 | 75 |  500 |  500 | 24.15 min | 60.553 % |\n","| 3   |  4321| 15 | 75 |  250 |  250 |  9.48 min | 60.591 % |\n","| 4   |  4321| 15 | 75 |  125 |  125 |  5.06 min | 60.501 % |\n","| 5   |  4321| 15 | 75 |   62 |   62 |  2.47 min | 60.360 % |"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4PobqJx-OM0Q"},"source":["# 결과 확인하기\n","- 3월 데이콘 대회 홈페이지 = https://bit.ly/39bqWVg\n","- 결과 제출하기 = https://dacon.io/competitions/official/235583/mysubmission/"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587422765295,"user_tz":-540,"elapsed":150842,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"-Ry1J9-SufLs","outputId":"84898434-f27d-4304-8428-204acae3c1f2","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["submission"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>winner</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.451333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.642882</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.366945</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.365370</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.751005</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7770</th>\n","      <td>0.364514</td>\n","    </tr>\n","    <tr>\n","      <th>7771</th>\n","      <td>0.365739</td>\n","    </tr>\n","    <tr>\n","      <th>7772</th>\n","      <td>0.584126</td>\n","    </tr>\n","    <tr>\n","      <th>7773</th>\n","      <td>0.712685</td>\n","    </tr>\n","    <tr>\n","      <th>7774</th>\n","      <td>0.444675</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7775 rows × 1 columns</p>\n","</div>"],"text/plain":["        winner\n","0     0.451333\n","1     0.642882\n","2     0.366945\n","3     0.365370\n","4     0.751005\n","...        ...\n","7770  0.364514\n","7771  0.365739\n","7772  0.584126\n","7773  0.712685\n","7774  0.444675\n","\n","[7775 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Zo8PYN93K8_C","colab_type":"code","outputId":"81a07dac-a73c-4465-fa35-90e3fd3f53e6","executionInfo":{"status":"ok","timestamp":1587422765296,"user_tz":-540,"elapsed":150832,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":639}},"source":["df_score.head(20)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>winner</th>\n","      <th>Y-pred</th>\n","      <th>Y</th>\n","      <th>check-sum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.451333</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.642882</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.366945</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.365370</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.751005</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.561527</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.433676</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.541490</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.742024</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.539299</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.229608</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.278919</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.505970</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.466033</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.307956</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.318704</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.640281</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.738414</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.483756</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.714345</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      winner  Y-pred  Y  check-sum\n","0   0.451333       0  0       True\n","1   0.642882       1  1       True\n","2   0.366945       0  0       True\n","3   0.365370       0  0       True\n","4   0.751005       1  0      False\n","5   0.561527       1  0      False\n","6   0.433676       0  0       True\n","7   0.541490       1  0      False\n","8   0.742024       1  1       True\n","9   0.539299       1  0      False\n","10  0.229608       0  0       True\n","11  0.278919       0  1      False\n","12  0.505970       1  0      False\n","13  0.466033       0  0       True\n","14  0.307956       0  1      False\n","15  0.318704       0  1      False\n","16  0.640281       1  1       True\n","17  0.738414       1  1       True\n","18  0.483756       0  0       True\n","19  0.714345       1  1       True"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"KaEQ00QmJI-0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}