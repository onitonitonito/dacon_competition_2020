{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"starcraft_XGBM_0415_startover_r01.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"187ugqNFuzIG"},"source":["### Install / Import 모듈 "]},{"cell_type":"markdown","metadata":{"id":"ijVfnIGhpSP7","colab_type":"text"},"source":["|   \n","|:--| \n","|<img src ='https://bit.ly/39XPeCc' width=200 align='left'>\n","|<h1>    starcraft_XGBM_0415_startover_r01.ipynb\n","</h1>    \n","\n","### **데이터 분리** (parametric study)\n","> - 80% 20%  Train/Test 자체 Test Data set 으로 모델을 검증 한다.\n","> - Sklearn.train_data_split() 을 이용해서 분리한다.\n","> - 파라메터를 바꿔 가면서 모델의 예측율을 사전 검증"]},{"cell_type":"code","metadata":{"id":"5sQxtIozpcwO","colab_type":"code","outputId":"72e37185-e8ee-4ce0-be43-f977bae7eeae","executionInfo":{"status":"ok","timestamp":1587435801506,"user_tz":-540,"elapsed":9644,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive \n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KHr7Oekx9AgU","outputId":"a54a0f79-3ae1-422b-debf-5f1679d1dc23","executionInfo":{"status":"ok","timestamp":1587435806157,"user_tz":-540,"elapsed":6786,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":181}},"source":["# 코랩에 없는 라이브러리 설치해주기\n","!pip install bayesian-optimization"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting bayesian-optimization\n","  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.2)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n","Installing collected packages: bayesian-optimization\n","Successfully installed bayesian-optimization-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ioj2p2hcpcsz","colab_type":"code","colab":{}},"source":["\"\"\"\n","# WAY-01 = LGBM, WAY-02 = XGBM\n","\"\"\"\n","\n","init_points, n_iter = (50, 20)                      \n","filename_submit = f\"submission_0415_XGBM_{init_points}_{n_iter}_startover_r01.csv\"\n","file_save = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VdrgC8ikqoWY","colab_type":"text"},"source":["## 사용함수의 정의"]},{"cell_type":"code","metadata":{"id":"qwEz7j19pcoc","colab_type":"code","colab":{}},"source":["\"\"\" \n","# 기본적인 module import 위치로 작업폴더 변경 getcwd() --> chidr()\n","# HOME 을 지정하고 작업폴더를 HOME 으로 변경.\n","\n","# # for PC\n","# import os\n","# HOME= 'dacon_competition_2020'\n","# dir_base = \"\".join(os.getcwd().partition(HOME)[:2]) + \"\\\\\"\n","# os.chdir(dir_base)  \n","\"\"\"   \n","\n","# for gDrive\n","import os\n","HOME = '/content/drive/My Drive/Colab Notebooks/'\n","os.chdir(HOME)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkRvo_w9prYc","colab_type":"code","outputId":"d07af502-995e-4ea9-b594-d3c9af078c82","executionInfo":{"status":"ok","timestamp":1587435819444,"user_tz":-540,"elapsed":5352,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["from _assets.config_dirs_gDrive import *\n","from _assets.modules import *\n","from _assets.module_xgbm_model import *"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","# FOR gDrive Colab - 화일분석에 필요한 공동폴더를 등록합니다.\n","# - echo = True : SYS.PATH INSERT 상황 보여줌\n","\n","\n","# OS 화일 및 DF 정보조회를 위한 탐색 모듈\n","\n","\n","# XGBM_CV 모델 - by SongDo_StudyGroup Code 참조\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O14CYkrx_Wvr","colab":{}},"source":["import os\n","import pandas as pd                         # 데이터 분석 라이브러리\n","import numpy as np                          # 계산 라이브러리\n","import matplotlib.pyplot as plt             # * 그래프 이미지\n","\n","from tqdm import tqdm                       # 진행바\n","\n","from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n","from sklearn.model_selection import KFold   # K-fold CV    \n","from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n","from functools import partial               # 함수 변수 고정\n","import lightgbm as lgb                      # LightGBM 라이브러리\n","import warnings           \n","import random                       \n","warnings.filterwarnings(\"ignore\")           # 경고 문구 미표시"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6anXmXEDqwwn","colab_type":"text"},"source":["## 데이터를 불러온다"]},{"cell_type":"code","metadata":{"id":"WhBuQT_EprPm","colab_type":"code","outputId":"eeaf684f-1821-4894-9a0b-21aab81b5f1b","executionInfo":{"status":"ok","timestamp":1587424945805,"user_tz":-540,"elapsed":38608,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%%time\n","\"\"\"\n","# show_infoDF_from(x_train) # *** DATA SHAPE = [ 38,872 x 1,579 ] \n","# to <class 'pandas.core.frame.DataFrame'>\n","# show_infoDF_from(y_train) # *** DATA SHAPE = [ 38,872 x 3 ]\n","# to <class 'numpy.ndarray'> ...  array([1, 1, 0, ..., 0, 1, 0])\n","\"\"\"\n","# x_train = pd.read_csv(dir_base + raw + 'xtra_remake_xtrain_final.csv')  \n","# ytrain = pd.read_csv(dir_base + remake + 'df_ytrain_remake.csv')  \n","# y_train = ytrain['winner'].values    \n","\n","\n","_df1 = pd.read_csv(dir_base + raw + 'X1_train.csv')\n","\n","x_train = _df1.iloc[:,:-1]              # pd.DataFrame\n","y_train = _df1.loc[:, 'Y'].to_numpy()   # np.array  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 73 ms, sys: 31.2 ms, total: 104 ms\n","Wall time: 2.67 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f0WBN5WXprLw","colab_type":"code","colab":{}},"source":["# x_train.shape, y_train.shape  # ((31097, 27), (31097,))\n","# type(y_train)                 # numpy.ndarray\n","# y_train                       # array([1, 1, 0, ..., 1, 1, 0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hbZfWk-F6_R_"},"source":["### Data 전처리 및 저장하기\n","- 전처리 된 x_train, y_train 내용을 확인하고, 저장한다."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587424945808,"user_tz":-540,"elapsed":38552,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"o7odz-aqnygj","outputId":"2de45562-b547-4a27-da0e-e80e451fdef0","colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["# 화일위치 / list 확인하기 ... 사용함수\n","# show_ls('/content')          # drive 가 붙었는지 확인!\n","show_ls(dir_base + raw)      # 불러올 Data 화일이름 확인!"],"execution_count":0,"outputs":[{"output_type":"stream","text":["False\n","DIR_TARGET=/content/drive/My Drive/Colab Notebooks\n","/content/drive/My Drive/Colab Notebooks/competition/c03_starcraft_prediction/data_raw/\n","----------------------------------------\n","  01. README_data_raw.md\n","  02. X1_test.csv\n","  03. X1_train.csv\n","  04. X2_test.csv\n","  05. X2_train.csv\n","  06. sample_submission.csv\n","  07. test.csv\n","  08. train.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lWHBjihKrhOE","colab_type":"text"},"source":["## XGBM Classifier 모델 적용\n"," - 송도 머신러닝 Sturdy 유창준님 파라메터 모델 공유 받음!\n"," -  Extreme Gradient Boost Method 적용 - [출처] :  YW & YY's Python, Machine & Deep Learning"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587431267394,"user_tz":-540,"elapsed":4509245,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"id":"Ny69by1mUWln","outputId":"8e0e1505-7c1b-4369-ca0b-82a39cf9b598","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","\n","var_fixed = partial(                       # 모델 그 외 변수는 고정\n","        XGB_cv, \n","        x_data=x_train, \n","        y_data=y_train, \n","        n_splits=5, \n","        output='score'\n","    )\n","\n","XGBo = BayesianOptimization(                # 베이지안 최적화 범위 설정\n","        var_fixed, \n","        {\n","            # 'colsample_bynode':(0, 1),    # unexpected argument in XGBM\n","            'colsample_bytree': (0.5, 1),   # 0.5 ~ 0.8\n","            'learning_rate': (0.1, 0.6),    # 0.6xxx\n","            # 'n_estimators' : (16, 62),    # unexpected argument in XGBM\n","            # 'num_leaves' : (16, 62),      # unexpected argument in XGBM\n","            'reg_alpha' : (7, 20),          # L1 - 7 ~ 20\n","            'reg_lambda' : (8, 50),         # L2 - 8 ~ 45\n","            'subsample': (0.5, 0.9),        # 0.5 ~ 0.7\n","         \n","\n","            'max_depth': (8, 512),          # ~ 500\n","            'max_delta_step' : (1, 25),     # 8.x\n","            'gamma' : (5, 20),              # 1 ~ 15\n","        },\n","        # random_state = random.randrange(50000) # 유동 시드 1~50000, 초기값\n","        random_state = random.randrange(50000) # 시드 고정 = 4321\n","    )\n","\n","# XGBo.maximize(init_points=15, n_iter=60)  # 처음 15회 랜덤값으로 score 계산 후 60회 최적화 = 4/04(토)\n","XGBo.maximize(init_points, n_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["|   iter    |  target   | colsam... |   gamma   | learni... | max_de... | max_depth | reg_alpha | reg_la... | subsample |\n","-------------------------------------------------------------------------------------------------------------------------\n","| \u001b[0m 1       \u001b[0m | \u001b[0m 0.637   \u001b[0m | \u001b[0m 0.7742  \u001b[0m | \u001b[0m 14.71   \u001b[0m | \u001b[0m 0.2321  \u001b[0m | \u001b[0m 17.25   \u001b[0m | \u001b[0m 363.9   \u001b[0m | \u001b[0m 19.62   \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 0.8955  \u001b[0m |\n","| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6306  \u001b[0m | \u001b[0m 0.6162  \u001b[0m | \u001b[0m 19.42   \u001b[0m | \u001b[0m 0.3904  \u001b[0m | \u001b[0m 7.261   \u001b[0m | \u001b[0m 256.4   \u001b[0m | \u001b[0m 10.37   \u001b[0m | \u001b[0m 42.0    \u001b[0m | \u001b[0m 0.5312  \u001b[0m |\n","| \u001b[95m 3       \u001b[0m | \u001b[95m 0.6417  \u001b[0m | \u001b[95m 0.9804  \u001b[0m | \u001b[95m 6.588   \u001b[0m | \u001b[95m 0.1989  \u001b[0m | \u001b[95m 23.69   \u001b[0m | \u001b[95m 251.4   \u001b[0m | \u001b[95m 8.492   \u001b[0m | \u001b[95m 40.21   \u001b[0m | \u001b[95m 0.5392  \u001b[0m |\n","| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6408  \u001b[0m | \u001b[0m 0.9462  \u001b[0m | \u001b[0m 9.748   \u001b[0m | \u001b[0m 0.1332  \u001b[0m | \u001b[0m 1.833   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 10.7    \u001b[0m | \u001b[0m 42.71   \u001b[0m | \u001b[0m 0.5824  \u001b[0m |\n","| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 0.9861  \u001b[0m | \u001b[0m 16.6    \u001b[0m | \u001b[0m 0.4328  \u001b[0m | \u001b[0m 1.746   \u001b[0m | \u001b[0m 344.5   \u001b[0m | \u001b[0m 12.81   \u001b[0m | \u001b[0m 24.37   \u001b[0m | \u001b[0m 0.678   \u001b[0m |\n","| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6385  \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 11.56   \u001b[0m | \u001b[0m 0.3019  \u001b[0m | \u001b[0m 13.17   \u001b[0m | \u001b[0m 272.7   \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 27.17   \u001b[0m | \u001b[0m 0.6759  \u001b[0m |\n","| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6333  \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 8.224   \u001b[0m | \u001b[0m 453.4   \u001b[0m | \u001b[0m 19.26   \u001b[0m | \u001b[0m 10.5    \u001b[0m | \u001b[0m 0.7891  \u001b[0m |\n","| \u001b[95m 8       \u001b[0m | \u001b[95m 0.6421  \u001b[0m | \u001b[95m 0.9586  \u001b[0m | \u001b[95m 8.6     \u001b[0m | \u001b[95m 0.215   \u001b[0m | \u001b[95m 16.62   \u001b[0m | \u001b[95m 16.49   \u001b[0m | \u001b[95m 8.444   \u001b[0m | \u001b[95m 35.57   \u001b[0m | \u001b[95m 0.5633  \u001b[0m |\n","| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 0.6151  \u001b[0m | \u001b[0m 9.27    \u001b[0m | \u001b[0m 0.1605  \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 224.3   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 10.75   \u001b[0m | \u001b[0m 0.6354  \u001b[0m |\n","| \u001b[95m 10      \u001b[0m | \u001b[95m 0.6422  \u001b[0m | \u001b[95m 0.6098  \u001b[0m | \u001b[95m 7.758   \u001b[0m | \u001b[95m 0.425   \u001b[0m | \u001b[95m 21.5    \u001b[0m | \u001b[95m 193.8   \u001b[0m | \u001b[95m 10.29   \u001b[0m | \u001b[95m 42.67   \u001b[0m | \u001b[95m 0.8968  \u001b[0m |\n","| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6353  \u001b[0m | \u001b[0m 0.9438  \u001b[0m | \u001b[0m 18.59   \u001b[0m | \u001b[0m 0.2033  \u001b[0m | \u001b[0m 13.22   \u001b[0m | \u001b[0m 10.8    \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 15.68   \u001b[0m | \u001b[0m 0.6975  \u001b[0m |\n","| \u001b[95m 12      \u001b[0m | \u001b[95m 0.6431  \u001b[0m | \u001b[95m 0.9847  \u001b[0m | \u001b[95m 6.438   \u001b[0m | \u001b[95m 0.1648  \u001b[0m | \u001b[95m 9.992   \u001b[0m | \u001b[95m 171.0   \u001b[0m | \u001b[95m 8.58    \u001b[0m | \u001b[95m 46.7    \u001b[0m | \u001b[95m 0.5244  \u001b[0m |\n","| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6344  \u001b[0m | \u001b[0m 0.682   \u001b[0m | \u001b[0m 18.43   \u001b[0m | \u001b[0m 0.2585  \u001b[0m | \u001b[0m 10.11   \u001b[0m | \u001b[0m 415.0   \u001b[0m | \u001b[0m 15.61   \u001b[0m | \u001b[0m 47.38   \u001b[0m | \u001b[0m 0.6662  \u001b[0m |\n","| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6406  \u001b[0m | \u001b[0m 0.7198  \u001b[0m | \u001b[0m 8.694   \u001b[0m | \u001b[0m 0.3409  \u001b[0m | \u001b[0m 14.11   \u001b[0m | \u001b[0m 352.0   \u001b[0m | \u001b[0m 11.72   \u001b[0m | \u001b[0m 49.44   \u001b[0m | \u001b[0m 0.7835  \u001b[0m |\n","| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6381  \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 0.3368  \u001b[0m | \u001b[0m 19.18   \u001b[0m | \u001b[0m 191.0   \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 27.02   \u001b[0m | \u001b[0m 0.5894  \u001b[0m |\n","| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6363  \u001b[0m | \u001b[0m 0.8853  \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 0.3217  \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 177.1   \u001b[0m | \u001b[0m 16.59   \u001b[0m | \u001b[0m 39.75   \u001b[0m | \u001b[0m 0.7485  \u001b[0m |\n","| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6369  \u001b[0m | \u001b[0m 0.9016  \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 0.171   \u001b[0m | \u001b[0m 4.717   \u001b[0m | \u001b[0m 360.9   \u001b[0m | \u001b[0m 14.99   \u001b[0m | \u001b[0m 9.614   \u001b[0m | \u001b[0m 0.5328  \u001b[0m |\n","| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6376  \u001b[0m | \u001b[0m 0.8326  \u001b[0m | \u001b[0m 16.37   \u001b[0m | \u001b[0m 0.406   \u001b[0m | \u001b[0m 16.16   \u001b[0m | \u001b[0m 190.9   \u001b[0m | \u001b[0m 8.965   \u001b[0m | \u001b[0m 9.143   \u001b[0m | \u001b[0m 0.8536  \u001b[0m |\n","| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6411  \u001b[0m | \u001b[0m 0.7981  \u001b[0m | \u001b[0m 9.339   \u001b[0m | \u001b[0m 0.2919  \u001b[0m | \u001b[0m 24.05   \u001b[0m | \u001b[0m 261.0   \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 49.65   \u001b[0m | \u001b[0m 0.6929  \u001b[0m |\n","| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.6301  \u001b[0m | \u001b[0m 15.85   \u001b[0m | \u001b[0m 0.4815  \u001b[0m | \u001b[0m 5.284   \u001b[0m | \u001b[0m 356.4   \u001b[0m | \u001b[0m 16.48   \u001b[0m | \u001b[0m 25.2    \u001b[0m | \u001b[0m 0.5646  \u001b[0m |\n","| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6366  \u001b[0m | \u001b[0m 0.9973  \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 0.4907  \u001b[0m | \u001b[0m 12.56   \u001b[0m | \u001b[0m 172.1   \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 25.7    \u001b[0m | \u001b[0m 0.7131  \u001b[0m |\n","| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 8.334   \u001b[0m | \u001b[0m 0.2384  \u001b[0m | \u001b[0m 9.833   \u001b[0m | \u001b[0m 294.0   \u001b[0m | \u001b[0m 17.59   \u001b[0m | \u001b[0m 49.56   \u001b[0m | \u001b[0m 0.5165  \u001b[0m |\n","| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.7899  \u001b[0m | \u001b[0m 19.36   \u001b[0m | \u001b[0m 0.3505  \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 189.3   \u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 16.69   \u001b[0m | \u001b[0m 0.55    \u001b[0m |\n","| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6376  \u001b[0m | \u001b[0m 0.5415  \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 0.3945  \u001b[0m | \u001b[0m 3.453   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 13.56   \u001b[0m | \u001b[0m 38.24   \u001b[0m | \u001b[0m 0.8171  \u001b[0m |\n","| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6374  \u001b[0m | \u001b[0m 0.8996  \u001b[0m | \u001b[0m 17.19   \u001b[0m | \u001b[0m 0.2905  \u001b[0m | \u001b[0m 9.203   \u001b[0m | \u001b[0m 46.31   \u001b[0m | \u001b[0m 9.723   \u001b[0m | \u001b[0m 21.57   \u001b[0m | \u001b[0m 0.8189  \u001b[0m |\n","| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6361  \u001b[0m | \u001b[0m 0.6914  \u001b[0m | \u001b[0m 15.56   \u001b[0m | \u001b[0m 0.3179  \u001b[0m | \u001b[0m 1.863   \u001b[0m | \u001b[0m 162.0   \u001b[0m | \u001b[0m 11.94   \u001b[0m | \u001b[0m 41.61   \u001b[0m | \u001b[0m 0.7     \u001b[0m |\n","| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.6466  \u001b[0m | \u001b[0m 9.293   \u001b[0m | \u001b[0m 0.1582  \u001b[0m | \u001b[0m 20.5    \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 16.86   \u001b[0m | \u001b[0m 39.04   \u001b[0m | \u001b[0m 0.7338  \u001b[0m |\n","| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6423  \u001b[0m | \u001b[0m 0.7463  \u001b[0m | \u001b[0m 9.047   \u001b[0m | \u001b[0m 0.1628  \u001b[0m | \u001b[0m 8.879   \u001b[0m | \u001b[0m 423.8   \u001b[0m | \u001b[0m 8.219   \u001b[0m | \u001b[0m 36.29   \u001b[0m | \u001b[0m 0.742   \u001b[0m |\n","| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6415  \u001b[0m | \u001b[0m 0.6045  \u001b[0m | \u001b[0m 5.883   \u001b[0m | \u001b[0m 0.2813  \u001b[0m | \u001b[0m 6.173   \u001b[0m | \u001b[0m 111.6   \u001b[0m | \u001b[0m 10.43   \u001b[0m | \u001b[0m 26.48   \u001b[0m | \u001b[0m 0.6938  \u001b[0m |\n","| \u001b[0m 30      \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.3242  \u001b[0m | \u001b[0m 13.68   \u001b[0m | \u001b[0m 510.1   \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 43.77   \u001b[0m | \u001b[0m 0.6792  \u001b[0m |\n","| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6385  \u001b[0m | \u001b[0m 0.7869  \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 23.6    \u001b[0m | \u001b[0m 168.0   \u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 49.92   \u001b[0m | \u001b[0m 0.6683  \u001b[0m |\n","| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.9543  \u001b[0m | \u001b[0m 11.24   \u001b[0m | \u001b[0m 0.4588  \u001b[0m | \u001b[0m 16.9    \u001b[0m | \u001b[0m 64.38   \u001b[0m | \u001b[0m 7.017   \u001b[0m | \u001b[0m 8.346   \u001b[0m | \u001b[0m 0.5786  \u001b[0m |\n","| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 0.8881  \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 0.2478  \u001b[0m | \u001b[0m 24.15   \u001b[0m | \u001b[0m 54.95   \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 22.5    \u001b[0m | \u001b[0m 0.5138  \u001b[0m |\n","| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6423  \u001b[0m | \u001b[0m 0.8153  \u001b[0m | \u001b[0m 6.373   \u001b[0m | \u001b[0m 0.2913  \u001b[0m | \u001b[0m 18.16   \u001b[0m | \u001b[0m 161.0   \u001b[0m | \u001b[0m 12.35   \u001b[0m | \u001b[0m 46.46   \u001b[0m | \u001b[0m 0.7529  \u001b[0m |\n","| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.9353  \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 0.4861  \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 36.79   \u001b[0m | \u001b[0m 7.306   \u001b[0m | \u001b[0m 16.97   \u001b[0m | \u001b[0m 0.797   \u001b[0m |\n","| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6355  \u001b[0m | \u001b[0m 0.7084  \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 0.4184  \u001b[0m | \u001b[0m 23.4    \u001b[0m | \u001b[0m 289.2   \u001b[0m | \u001b[0m 16.03   \u001b[0m | \u001b[0m 30.46   \u001b[0m | \u001b[0m 0.528   \u001b[0m |\n","| \u001b[95m 37      \u001b[0m | \u001b[95m 0.6436  \u001b[0m | \u001b[95m 0.8125  \u001b[0m | \u001b[95m 5.263   \u001b[0m | \u001b[95m 0.1917  \u001b[0m | \u001b[95m 21.98   \u001b[0m | \u001b[95m 99.43   \u001b[0m | \u001b[95m 11.44   \u001b[0m | \u001b[95m 20.37   \u001b[0m | \u001b[95m 0.8304  \u001b[0m |\n","| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6371  \u001b[0m | \u001b[0m 0.5953  \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m 23.93   \u001b[0m | \u001b[0m 40.16   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 34.09   \u001b[0m | \u001b[0m 0.6301  \u001b[0m |\n","| \u001b[0m 39      \u001b[0m | \u001b[0m 0.6342  \u001b[0m | \u001b[0m 0.8203  \u001b[0m | \u001b[0m 15.54   \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 22.95   \u001b[0m | \u001b[0m 182.0   \u001b[0m | \u001b[0m 16.52   \u001b[0m | \u001b[0m 42.39   \u001b[0m | \u001b[0m 0.8751  \u001b[0m |\n","| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6351  \u001b[0m | \u001b[0m 0.6475  \u001b[0m | \u001b[0m 19.29   \u001b[0m | \u001b[0m 0.2314  \u001b[0m | \u001b[0m 17.56   \u001b[0m | \u001b[0m 253.2   \u001b[0m | \u001b[0m 11.68   \u001b[0m | \u001b[0m 31.61   \u001b[0m | \u001b[0m 0.8345  \u001b[0m |\n","| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6344  \u001b[0m | \u001b[0m 0.589   \u001b[0m | \u001b[0m 11.07   \u001b[0m | \u001b[0m 0.5751  \u001b[0m | \u001b[0m 7.023   \u001b[0m | \u001b[0m 318.5   \u001b[0m | \u001b[0m 18.87   \u001b[0m | \u001b[0m 48.68   \u001b[0m | \u001b[0m 0.5762  \u001b[0m |\n","| \u001b[0m 42      \u001b[0m | \u001b[0m 0.635   \u001b[0m | \u001b[0m 0.8121  \u001b[0m | \u001b[0m 15.26   \u001b[0m | \u001b[0m 0.5725  \u001b[0m | \u001b[0m 9.431   \u001b[0m | \u001b[0m 389.7   \u001b[0m | \u001b[0m 15.85   \u001b[0m | \u001b[0m 9.417   \u001b[0m | \u001b[0m 0.614   \u001b[0m |\n","| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6348  \u001b[0m | \u001b[0m 0.6908  \u001b[0m | \u001b[0m 11.67   \u001b[0m | \u001b[0m 0.3509  \u001b[0m | \u001b[0m 4.693   \u001b[0m | \u001b[0m 242.9   \u001b[0m | \u001b[0m 19.6    \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.507   \u001b[0m |\n","| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6366  \u001b[0m | \u001b[0m 0.9107  \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 0.3346  \u001b[0m | \u001b[0m 12.32   \u001b[0m | \u001b[0m 68.35   \u001b[0m | \u001b[0m 13.23   \u001b[0m | \u001b[0m 14.39   \u001b[0m | \u001b[0m 0.6549  \u001b[0m |\n","| \u001b[0m 45      \u001b[0m | \u001b[0m 0.6339  \u001b[0m | \u001b[0m 0.9526  \u001b[0m | \u001b[0m 18.18   \u001b[0m | \u001b[0m 0.1502  \u001b[0m | \u001b[0m 6.923   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 11.77   \u001b[0m | \u001b[0m 0.5049  \u001b[0m |\n","| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6348  \u001b[0m | \u001b[0m 0.6519  \u001b[0m | \u001b[0m 7.267   \u001b[0m | \u001b[0m 0.518   \u001b[0m | \u001b[0m 16.8    \u001b[0m | \u001b[0m 296.9   \u001b[0m | \u001b[0m 12.94   \u001b[0m | \u001b[0m 8.188   \u001b[0m | \u001b[0m 0.6462  \u001b[0m |\n","| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6356  \u001b[0m | \u001b[0m 0.6004  \u001b[0m | \u001b[0m 15.5    \u001b[0m | \u001b[0m 0.5265  \u001b[0m | \u001b[0m 21.62   \u001b[0m | \u001b[0m 284.0   \u001b[0m | \u001b[0m 13.4    \u001b[0m | \u001b[0m 35.82   \u001b[0m | \u001b[0m 0.8058  \u001b[0m |\n","| \u001b[0m 48      \u001b[0m | \u001b[0m 0.6397  \u001b[0m | \u001b[0m 0.7867  \u001b[0m | \u001b[0m 8.315   \u001b[0m | \u001b[0m 0.3404  \u001b[0m | \u001b[0m 7.564   \u001b[0m | \u001b[0m 292.0   \u001b[0m | \u001b[0m 19.3    \u001b[0m | \u001b[0m 26.08   \u001b[0m | \u001b[0m 0.6496  \u001b[0m |\n","| \u001b[0m 49      \u001b[0m | \u001b[0m 0.636   \u001b[0m | \u001b[0m 0.9849  \u001b[0m | \u001b[0m 5.389   \u001b[0m | \u001b[0m 0.4237  \u001b[0m | \u001b[0m 12.42   \u001b[0m | \u001b[0m 89.86   \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 42.1    \u001b[0m | \u001b[0m 0.7311  \u001b[0m |\n","| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6399  \u001b[0m | \u001b[0m 0.6487  \u001b[0m | \u001b[0m 10.34   \u001b[0m | \u001b[0m 0.3643  \u001b[0m | \u001b[0m 3.974   \u001b[0m | \u001b[0m 385.1   \u001b[0m | \u001b[0m 9.615   \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 0.7254  \u001b[0m |\n","| \u001b[0m 51      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 0.8123  \u001b[0m | \u001b[0m 5.49    \u001b[0m | \u001b[0m 0.4136  \u001b[0m | \u001b[0m 24.17   \u001b[0m | \u001b[0m 501.8   \u001b[0m | \u001b[0m 9.518   \u001b[0m | \u001b[0m 8.149   \u001b[0m | \u001b[0m 0.7155  \u001b[0m |\n","| \u001b[0m 52      \u001b[0m | \u001b[0m 0.6417  \u001b[0m | \u001b[0m 0.667   \u001b[0m | \u001b[0m 5.272   \u001b[0m | \u001b[0m 0.2803  \u001b[0m | \u001b[0m 1.298   \u001b[0m | \u001b[0m 485.0   \u001b[0m | \u001b[0m 16.48   \u001b[0m | \u001b[0m 45.34   \u001b[0m | \u001b[0m 0.7294  \u001b[0m |\n","| \u001b[0m 53      \u001b[0m | \u001b[0m 0.638   \u001b[0m | \u001b[0m 0.5319  \u001b[0m | \u001b[0m 11.25   \u001b[0m | \u001b[0m 0.5901  \u001b[0m | \u001b[0m 5.195   \u001b[0m | \u001b[0m 423.5   \u001b[0m | \u001b[0m 7.255   \u001b[0m | \u001b[0m 35.49   \u001b[0m | \u001b[0m 0.6346  \u001b[0m |\n","| \u001b[0m 54      \u001b[0m | \u001b[0m 0.6424  \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 9.688   \u001b[0m | \u001b[0m 0.1701  \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 13.79   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 8.616   \u001b[0m | \u001b[0m 0.8478  \u001b[0m |\n","| \u001b[0m 55      \u001b[0m | \u001b[0m 0.6229  \u001b[0m | \u001b[0m 0.9074  \u001b[0m | \u001b[0m 5.098   \u001b[0m | \u001b[0m 0.5555  \u001b[0m | \u001b[0m 1.969   \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 12.28   \u001b[0m | \u001b[0m 8.525   \u001b[0m | \u001b[0m 0.6882  \u001b[0m |\n","| \u001b[95m 56      \u001b[0m | \u001b[95m 0.6438  \u001b[0m | \u001b[95m 0.914   \u001b[0m | \u001b[95m 5.134   \u001b[0m | \u001b[95m 0.1599  \u001b[0m | \u001b[95m 19.91   \u001b[0m | \u001b[95m 494.3   \u001b[0m | \u001b[95m 18.83   \u001b[0m | \u001b[95m 49.88   \u001b[0m | \u001b[95m 0.8529  \u001b[0m |\n","| \u001b[0m 57      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 0.4195  \u001b[0m | \u001b[0m 22.88   \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 8.244   \u001b[0m | \u001b[0m 41.26   \u001b[0m | \u001b[0m 0.7765  \u001b[0m |\n","| \u001b[0m 58      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.7832  \u001b[0m | \u001b[0m 7.358   \u001b[0m | \u001b[0m 0.5332  \u001b[0m | \u001b[0m 22.76   \u001b[0m | \u001b[0m 463.0   \u001b[0m | \u001b[0m 7.704   \u001b[0m | \u001b[0m 49.45   \u001b[0m | \u001b[0m 0.8183  \u001b[0m |\n","| \u001b[0m 59      \u001b[0m | \u001b[0m 0.6425  \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 5.045   \u001b[0m | \u001b[0m 0.1654  \u001b[0m | \u001b[0m 20.82   \u001b[0m | \u001b[0m 419.1   \u001b[0m | \u001b[0m 19.12   \u001b[0m | \u001b[0m 45.49   \u001b[0m | \u001b[0m 0.6129  \u001b[0m |\n","| \u001b[0m 60      \u001b[0m | \u001b[0m 0.6433  \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 7.117   \u001b[0m | \u001b[0m 0.1523  \u001b[0m | \u001b[0m 2.132   \u001b[0m | \u001b[0m 510.9   \u001b[0m | \u001b[0m 7.009   \u001b[0m | \u001b[0m 42.86   \u001b[0m | \u001b[0m 0.8606  \u001b[0m |\n","| \u001b[95m 61      \u001b[0m | \u001b[95m 0.6445  \u001b[0m | \u001b[95m 0.8466  \u001b[0m | \u001b[95m 5.557   \u001b[0m | \u001b[95m 0.1095  \u001b[0m | \u001b[95m 24.75   \u001b[0m | \u001b[95m 309.3   \u001b[0m | \u001b[95m 8.802   \u001b[0m | \u001b[95m 49.97   \u001b[0m | \u001b[95m 0.8112  \u001b[0m |\n","| \u001b[0m 62      \u001b[0m | \u001b[0m 0.6429  \u001b[0m | \u001b[0m 0.7106  \u001b[0m | \u001b[0m 5.199   \u001b[0m | \u001b[0m 0.1658  \u001b[0m | \u001b[0m 1.748   \u001b[0m | \u001b[0m 511.4   \u001b[0m | \u001b[0m 17.84   \u001b[0m | \u001b[0m 48.17   \u001b[0m | \u001b[0m 0.5837  \u001b[0m |\n","| \u001b[0m 63      \u001b[0m | \u001b[0m 0.6441  \u001b[0m | \u001b[0m 0.8613  \u001b[0m | \u001b[0m 5.274   \u001b[0m | \u001b[0m 0.122   \u001b[0m | \u001b[0m 23.67   \u001b[0m | \u001b[0m 138.6   \u001b[0m | \u001b[0m 8.461   \u001b[0m | \u001b[0m 28.59   \u001b[0m | \u001b[0m 0.8774  \u001b[0m |\n","| \u001b[0m 64      \u001b[0m | \u001b[0m 0.644   \u001b[0m | \u001b[0m 0.9066  \u001b[0m | \u001b[0m 5.27    \u001b[0m | \u001b[0m 0.1394  \u001b[0m | \u001b[0m 1.048   \u001b[0m | \u001b[0m 397.7   \u001b[0m | \u001b[0m 16.21   \u001b[0m | \u001b[0m 36.4    \u001b[0m | \u001b[0m 0.7837  \u001b[0m |\n","| \u001b[0m 65      \u001b[0m | \u001b[0m 0.6445  \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 5.075   \u001b[0m | \u001b[0m 0.1209  \u001b[0m | \u001b[0m 19.0    \u001b[0m | \u001b[0m 401.1   \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 33.16   \u001b[0m | \u001b[0m 0.8366  \u001b[0m |\n","| \u001b[0m 66      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 0.9714  \u001b[0m | \u001b[0m 5.562   \u001b[0m | \u001b[0m 0.1624  \u001b[0m | \u001b[0m 22.84   \u001b[0m | \u001b[0m 13.5    \u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 35.58   \u001b[0m | \u001b[0m 0.8965  \u001b[0m |\n","| \u001b[0m 67      \u001b[0m | \u001b[0m 0.6436  \u001b[0m | \u001b[0m 0.7747  \u001b[0m | \u001b[0m 5.501   \u001b[0m | \u001b[0m 0.1307  \u001b[0m | \u001b[0m 3.917   \u001b[0m | \u001b[0m 209.5   \u001b[0m | \u001b[0m 10.2    \u001b[0m | \u001b[0m 38.15   \u001b[0m | \u001b[0m 0.8427  \u001b[0m |\n","| \u001b[0m 68      \u001b[0m | \u001b[0m 0.641   \u001b[0m | \u001b[0m 0.9974  \u001b[0m | \u001b[0m 5.622   \u001b[0m | \u001b[0m 0.1877  \u001b[0m | \u001b[0m 14.71   \u001b[0m | \u001b[0m 117.8   \u001b[0m | \u001b[0m 9.107   \u001b[0m | \u001b[0m 8.421   \u001b[0m | \u001b[0m 0.7464  \u001b[0m |\n","| \u001b[0m 69      \u001b[0m | \u001b[0m 0.6317  \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 5.147   \u001b[0m | \u001b[0m 0.4697  \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 96.65   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 18.47   \u001b[0m | \u001b[0m 0.66    \u001b[0m |\n","| \u001b[0m 70      \u001b[0m | \u001b[0m 0.6445  \u001b[0m | \u001b[0m 0.8989  \u001b[0m | \u001b[0m 5.003   \u001b[0m | \u001b[0m 0.1151  \u001b[0m | \u001b[0m 8.521   \u001b[0m | \u001b[0m 406.7   \u001b[0m | \u001b[0m 11.52   \u001b[0m | \u001b[0m 15.3    \u001b[0m | \u001b[0m 0.86    \u001b[0m |\n","=========================================================================================================================\n","CPU times: user 1h 45min 17s, sys: 17.4 s, total: 1h 45min 34s\n","Wall time: 1h 45min 21s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CfHi_LZ4O1_l"},"source":["### 3.0 모델 학습 및 검증\n","- Model Tuning & Evaluation\n","\n","> 1. AUC가 가장 높은 하이퍼 파라미터를 사용해 최종 모델을 얻습니다.\n","> 1. 훈련 세트와 같은 방법으로 테스트 세트에서 Feature를 추출합니다.\n","> 1. 최종 모델을 사용해 예측을 수행합니다.\n","> 1. 예측 결과를 submission.csv로 저장합니다.\n","\n","| ITER | TARGET | COLSAMPLE | GAMMA | LEARN_RATE | MAX_DELTA | MAX_DEPTH | REG_ALPHA | REG_LAMBDA | SUBSAMPLE |\n","|--|--|--|--|--|--|--|--|--|--|\n","|  1        |  0.637    |  0.7742   |  14.71    |  0.2321   |  17.25    |  363.9    |  19.62    |  12.76    |  0.8955   |\n","|  2        |  0.6306   |  0.6162   |  19.42    |  0.3904   |  7.261    |  256.4    |  10.37    |  42.0     |  0.5312   |\n","|  3        |  0.6417   |  0.9804   |  6.588    |  0.1989   |  23.69    |  251.4    |  8.492    |  40.21    |  0.5392   |\n","|  4        |  0.6408   |  0.9462   |  9.748    |  0.1332   |  1.833    |  308.2    |  10.7     |  42.71    |  0.5824   |\n","|  5        |  0.6359   |  0.9861   |  16.6     |  0.4328   |  1.746    |  344.5    |  12.81    |  24.37    |  0.678    |\n","|  6        |  0.6385   |  0.6523   |  11.56    |  0.3019   |  13.17    |  272.7    |  12.36    |  27.17    |  0.6759   |\n","|  7        |  0.6333   |  0.5475   |  14.89    |  0.4889   |  8.224    |  453.4    |  19.26    |  10.5     |  0.7891   |\n","|  8        |  0.6421   |  0.9586   |  8.6      |  0.215    |  16.62    |  16.49    |  8.444    |  35.57    |  0.5633   |\n","|  9        |  0.6409   |  0.6151   |  9.27     |  0.1605   |  3.964    |  224.3    |  14.69    |  10.75    |  0.6354   |\n","|  10       |  0.6422   |  0.6098   |  7.758    |  0.425    |  21.5     |  193.8    |  10.29    |  42.67    |  0.8968   |\n","|  11       |  0.6353   |  0.9438   |  18.59    |  0.2033   |  13.22    |  10.8     |  19.54    |  15.68    |  0.6975   |\n","|  12       |  0.6431   |  0.9847   |  6.438    |  0.1648   |  9.992    |  171.0    |  8.58     |  46.7     |  0.5244   |\n","|  13       |  0.6344   |  0.682    |  18.43    |  0.2585   |  10.11    |  415.0    |  15.61    |  47.38    |  0.6662   |\n","|  14       |  0.6406   |  0.7198   |  8.694    |  0.3409   |  14.11    |  352.0    |  11.72    |  49.44    |  0.7835   |\n","|  15       |  0.6381   |  0.9125   |  10.76    |  0.3368   |  19.18    |  191.0    |  19.37    |  27.02    |  0.5894   |\n","|  16       |  0.6363   |  0.8853   |  17.32    |  0.3217   |  12.2     |  177.1    |  16.59    |  39.75    |  0.7485   |\n","|  17       |  0.6369   |  0.9016   |  14.5     |  0.171    |  4.717    |  360.9    |  14.99    |  9.614    |  0.5328   |\n","|  18       |  0.6376   |  0.8326   |  16.37    |  0.406    |  16.16    |  190.9    |  8.965    |  9.143    |  0.8536   |\n","|  19       |  0.6411   |  0.7981   |  9.339    |  0.2919   |  24.05    |  261.0    |  11.92    |  49.65    |  0.6929   |\n","|  20       |  0.6318   |  0.6301   |  15.85    |  0.4815   |  5.284    |  356.4    |  16.48    |  25.2     |  0.5646   |"]},{"cell_type":"markdown","metadata":{"id":"E7cjTFOpyDnU","colab_type":"text"},"source":["# XGBM Parametric Study\n","\n","| NUM | SEED | RANDOM | ITERATION | n_ESTIMATION | num_LEAF | TIME_SPEND| PREDICTION |\n","|:---:|-----:|---:|---:|-----:|-----:|----------:|:--------:|\n","|  1  | 50000|    |    |      |      | 1.45.21 s | 60.875 % |\n","|     | 50000|    |    |      |      | -.--.-- s | --.000 % |\n","|     | 50000|    |    |      |      | -.--.-- s | --.000 % |\n","|     | 50000|    |    |      |      | -.--.-- s | --.000 % |"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7UMIvW62UWhn","colab":{}},"source":["\"\"\"\n","# xgb.cv: Cross Validation documentation\n","# https://rdrr.io/cran/xgboost/man/xgb.cv.html\n","\"\"\"\n","\n","params = XGBo.max['params']\n","\n","models = XGB_cv(                    # cv = cross validation\n","        max_depth =        params['max_depth'], \n","        learning_rate =    params['learning_rate'],\n","        subsample =        params['subsample'], \n","        colsample_bytree = params['colsample_bytree'], \n","        reg_alpha =        params['reg_alpha'], \n","        reg_lambda =       params['reg_lambda'],\n","        gamma =            params['gamma'],\n","        max_delta_step =   params['max_delta_step'],\n","        x_data=x_train, \n","        y_data=y_train, \n","        n_splits=5, \n","        output='model'\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W9d6ImndX5zO"},"source":["# TEST를 풀기위해, 학습데이터로 변경 (data_preps)\n"," 1. Train Data set = [ 67,091,776 x 7 ] ... 70%\n","  - game_id 별로 정리하면 [38,872 x 27]로 압축된다. \n","  - 경기당, 평균 1,726개의 이벤트가 존재한다.(압축률 0.057939 %)\n"," > - x_train set = *** DATA SHAPE = [ 38,872 x 27 ] pandas.DataFrame\n"," > - y_train set = *** DATA SHAPE = [ 38,872 x 1 ]  np.array\n"," \n"," 1. Test Data set  = [ 28,714,849 x 6 ] ... 30%\n","  - game_id 별로 정리하면 [16,787 x 27] 로 압축된다. \n","  - 경기당 평균 1711개의 이벤트가 존재한다.(압축률 0.058461 %)\n"," > - x_test set = *** DATA SHAPE = [16,787 x 27] pandas.DataFrame \n"," > - y_test set = *** DATA SHAPE = [16,787 x 1] np.array =  대회주관자가 가지고 있음\n"," \n"," 1. Submission = y_test set \n","  - submission = [16,787 x 1] np.array to [16,787 x 2 ] pandas.DataFrame --> df.csv"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"20YeuGYXUWZ3","colab":{}},"source":["\"\"\"\n","# 테스트용 데이터를 전처리 해서 분석 준비 ... (시간소요) 미리 저장한 화일을 불러온다\n","# 저장했으면 비활성 처리\n","# x_test, _ = data_preparation(test, answer=False)                 # [ 28,714,849 x 6 ] ... 30%\n","# x_test.to_csv(dir_base + remake + 'df_xtest_remake.csv')\n","# x_test = pd.read_csv(dir_base + remake + 'df_xtest_remake.csv')  # [  16,787 x 27 ]\n","\"\"\"\n","# x_test = pd.read_csv(dir_base + remake + 'xtra_remake_xtest_final.csv')    # *** DATA SHAPE = [ 16,787 x 27 ]\n","\n","_df2 = pd.read_csv(dir_base + raw + 'X1_test.csv')\n","x_test = _df2.iloc[:,:-1]\n","y_test = _df2.loc[:, 'Y']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMzm2CmXxu8z","colab_type":"code","outputId":"b784ff8d-db6a-4881-bd1a-b74b3da6448f","executionInfo":{"status":"ok","timestamp":1587431377941,"user_tz":-540,"elapsed":208,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["x_test.shape, y_test.shape  # ((31097, 27), (31097,))\n","type(y_test)                 # numpy.ndarray\n","y_test                       # array([1, 1, 0, ..., 1, 1, 0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       1\n","2       0\n","3       0\n","4       0\n","       ..\n","7770    1\n","7771    0\n","7772    0\n","7773    1\n","7774    0\n","Name: Y, Length: 7775, dtype: int64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"IA3z8upDpLS5","colab_type":"text"},"source":["# 예측결과 Submission 화일 만들기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k9HevRoDUWUC","colab":{}},"source":["\"\"\"\n","# pd.read_csv('data/sample_submission.csv', index_col=0)\n","# sample_submission = pd.read_csv(dir_base + sub_base + \"sample_submission.csv\")\n","\"\"\"\n","\n","preds = []\n","\n","for model in models:\n","    pred = model.predict_proba(x_test)[:, 1]\n","    preds.append(pred)\n","    \n","pred = np.mean(preds, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbRStbNrx3To","colab_type":"code","colab":{}},"source":["\"\"\"\n","# submission = pd.read_csv(dir_base + raw + \"sample_submission.csv\", index_col='game_id') \n","# submission = pd.DataFrame(pred, columns=['winner'])\n","\n","# submission['winner'] = pred\n","\"\"\"\n","\n","\n","submission = pd.DataFrame(pred, columns=['winner'])\n","# submission.to_csv(dir_base + submit + filename_submit, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xn6I-DfxpLTD","colab_type":"code","outputId":"66859077-03c9-4633-84d7-b9d1a0f35df3","executionInfo":{"status":"ok","timestamp":1587431377948,"user_tz":-540,"elapsed":163,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\"\"\"\n","# submission = pd.read_csv(dir_base + raw + \"sample_submission.csv\") \n","# submission['winner'] = pred\n","\"\"\"\n","if file_save:\n","    submission.to_csv(dir_base + submit + filename_submit, index=False)\n","else:\n","    print('*** SAVING FILE SKIPPED!! ***')    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["*** SAVING FILE SKIPPED!! ***\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xo1wWuCqx3Pf","colab_type":"code","outputId":"b3aefdfe-d576-4a9b-a88d-60b01237777b","executionInfo":{"status":"ok","timestamp":1587431377949,"user_tz":-540,"elapsed":147,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\"\"\"\n","#  자체 스코어를 파악해 본다 = 정답률 60.37 % \n","# - True     4694\n","# - False    3081\n","\"\"\"\n","\n","df_score =  submission.copy()             # deep copy\n","df_score['Y-pred'] = df_score.winner.apply(lambda x: 1 if x > 0.5 else 0)\n","df_score['Y'] = y_test\n","df_score['check-sum'] = (df_score['Y-pred'] == df_score['Y'])\n","\n","_ = df_score['check-sum'].value_counts().to_list()\n","score = _[0]/(_[0]+_[1])\n","print(f\"*** SCORE = {score * 100:0.7} %\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["*** SCORE = 60.8746 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4PobqJx-OM0Q"},"source":["# 결과 확인하기\n","- 3월 데이콘 대회 홈페이지 = https://bit.ly/39bqWVg\n","- 결과 제출하기 = https://dacon.io/competitions/official/235583/mysubmission/"]},{"cell_type":"code","metadata":{"id":"6_dbkj47pLTL","colab_type":"code","outputId":"4d099ec9-a342-4f13-aec5-8c7004be4f70","executionInfo":{"status":"ok","timestamp":1587431377950,"user_tz":-540,"elapsed":126,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["submission"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>winner</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.424345</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.639418</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.340709</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.364041</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.765779</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7770</th>\n","      <td>0.399698</td>\n","    </tr>\n","    <tr>\n","      <th>7771</th>\n","      <td>0.361303</td>\n","    </tr>\n","    <tr>\n","      <th>7772</th>\n","      <td>0.587917</td>\n","    </tr>\n","    <tr>\n","      <th>7773</th>\n","      <td>0.732650</td>\n","    </tr>\n","    <tr>\n","      <th>7774</th>\n","      <td>0.451226</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7775 rows × 1 columns</p>\n","</div>"],"text/plain":["        winner\n","0     0.424345\n","1     0.639418\n","2     0.340709\n","3     0.364041\n","4     0.765779\n","...        ...\n","7770  0.399698\n","7771  0.361303\n","7772  0.587917\n","7773  0.732650\n","7774  0.451226\n","\n","[7775 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"rW42DTuBz7Vg","colab_type":"code","outputId":"735b500a-a8d5-41bc-e06f-df665ea85cc7","executionInfo":{"status":"ok","timestamp":1587431378021,"user_tz":-540,"elapsed":163,"user":{"displayName":"SuParX -K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAhLtiQrZfK-FHgn5GBmgExX619ygpOPHHdN4ZkU0=s64","userId":"05876132496561296136"}},"colab":{"base_uri":"https://localhost:8080/","height":669}},"source":["df_score.head(20)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>winner</th>\n","      <th>Y-pred</th>\n","      <th>Y</th>\n","      <th>check-sum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.424345</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.639418</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.340709</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.364041</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.765779</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.549900</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.406670</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.530096</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.756660</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.551271</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.241571</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.273976</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.506486</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.462050</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.305827</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.310225</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.649397</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.749657</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.453446</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.692334</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      winner  Y-pred  Y  check-sum\n","0   0.424345       0  0       True\n","1   0.639418       1  1       True\n","2   0.340709       0  0       True\n","3   0.364041       0  0       True\n","4   0.765779       1  0      False\n","5   0.549900       1  0      False\n","6   0.406670       0  0       True\n","7   0.530096       1  0      False\n","8   0.756660       1  1       True\n","9   0.551271       1  0      False\n","10  0.241571       0  0       True\n","11  0.273976       0  1      False\n","12  0.506486       1  0      False\n","13  0.462050       0  0       True\n","14  0.305827       0  1      False\n","15  0.310225       0  1      False\n","16  0.649397       1  1       True\n","17  0.749657       1  1       True\n","18  0.453446       0  0       True\n","19  0.692334       1  1       True"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"kzyfceGdz9-Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}